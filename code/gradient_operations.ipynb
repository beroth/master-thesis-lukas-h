{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-18T21:08:25.163298Z",
     "start_time": "2024-09-18T21:08:19.315970Z"
    }
   },
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_from_disk\n",
    "\n",
    "from config import hf_model_id, lima_filtered_paraphrased_dataset_path\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import gc\n",
    "\n",
    "from utilities.preprocessing import prepare_dataset\n",
    "from utilities.gradient_operations import get_gradients, get_flattened_weight_vector"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lukashinterleitner/anaconda3/envs/master-thesis/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-09-18 23:08:22,416] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lukashinterleitner/anaconda3/envs/master-thesis/compiler_compat/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "/home/lukashinterleitner/anaconda3/envs/master-thesis/compiler_compat/ld: cannot find -lcufile: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T21:09:33.771863Z",
     "start_time": "2024-09-18T21:09:33.758695Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ],
   "id": "af748f64e20a4fa8",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T21:09:36.804059Z",
     "start_time": "2024-09-18T21:09:36.510812Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ],
   "id": "cdeb08b4f6d2957",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T21:09:40.952421Z",
     "start_time": "2024-09-18T21:09:39.779018Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(hf_model_id)\n",
    "tokenizer = AutoTokenizer.from_pretrained(hf_model_id)\n",
    "\n",
    "print(tokenizer.eos_token_id)\n",
    "print(tokenizer.pad_token_id)"
   ],
   "id": "addc6245190d0ee2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50279\n",
      "1\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T21:09:43.332313Z",
     "start_time": "2024-09-18T21:09:43.320929Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ],
   "id": "c64e2b22c156b3f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T21:09:46.458162Z",
     "start_time": "2024-09-18T21:09:46.441044Z"
    }
   },
   "cell_type": "code",
   "source": "model.eval()",
   "id": "1b5ea9b4364e38c2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OlmoForCausalLM(\n",
       "  (model): OlmoModel(\n",
       "    (embed_tokens): Embedding(50304, 2048, padding_idx=1)\n",
       "    (layers): ModuleList(\n",
       "      (0-15): 16 x OlmoDecoderLayer(\n",
       "        (self_attn): OlmoSdpaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): OlmoRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): OlmoMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): OlmoLayerNorm()\n",
       "        (post_attention_layernorm): OlmoLayerNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): OlmoLayerNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=50304, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T21:10:09.936772Z",
     "start_time": "2024-09-18T21:10:09.918812Z"
    }
   },
   "cell_type": "code",
   "source": "dataset = load_from_disk(lima_filtered_paraphrased_dataset_path)",
   "id": "b94aff18b2d7ddec",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T21:10:14.247759Z",
     "start_time": "2024-09-18T21:10:10.837609Z"
    }
   },
   "cell_type": "code",
   "source": "train_dataloader = prepare_dataset(dataset=dataset, model=model, tokenizer=tokenizer)",
   "id": "7f41a2fe2aa324e8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing and reformatting instruction data: 100%|██████████| 988/988 [00:03<00:00, 304.85 examples/s]\n",
      "Filter: 100%|██████████| 988/988 [00:00<00:00, 11492.90 examples/s]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T21:15:22.539399Z",
     "start_time": "2024-09-18T21:15:11.218892Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sample_0 = list(train_dataloader)[0]\n",
    "\n",
    "gradients_sample_0 = get_gradients(model, sample_0)"
   ],
   "id": "5e53c8a11abe6c32",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T21:15:28.906278Z",
     "start_time": "2024-09-18T21:15:28.878979Z"
    }
   },
   "cell_type": "code",
   "source": "sample_0",
   "id": "12cc6b434ba40cf6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[   29,    93,  4537, 49651,   187,  5804,  3998,  1341,  2118,    32,\n",
       "          2896,  4866,   309,  1599,  1048,  4181, 10346,   313, 11499, 31821,\n",
       "          1561,   253,  3998,   760,   481,   187,    29,    93,   515,  5567,\n",
       "         49651,   187,   510,  1953,   310,  4942,  3862,   285,   581,   943,\n",
       "          1379,   715,  2395,   326,   253,  3998,   417,   760,  8414,   273,\n",
       "          8512,    13,   533,   671, 42782,  1341,   313, 13821,   422,  1341,\n",
       "            10,   285,   638,    14,  2225,  3875, 16069,  8424,  1341,    15,\n",
       "          5488,    13,   347,  4619,  7715,    14, 30202,  1346,   452,  4860,\n",
       "            13, 16743,  3924,   310,  1077,  1774,    13,   347,   253,  6684,\n",
       "         24022,  3998,   310,  1077,  1027,   432,   253,  6782,  3998,    15,\n",
       "           187,  6436,    13,   846,   256, 12545,   949,  2710, 16516,    13,\n",
       "           253,  3662,   281,   253,  1953,   310,  2686, 24678,  2969,    27,\n",
       "          6279,    13,  3998,  1341, 31690,    15,   187,   688, 50276,   783,\n",
       "          6782,  3998, 42782,  1341, 31690,   275,   253,  3998,   313,    44,\n",
       "         42824,  1814,    85,    13,  4748,   481,  4051,   451,  1341,   403,\n",
       "          3206,   275,   247, 35988,   273,  3470,    13,   533,   247, 16613,\n",
       "          1650,   273, 46447, 42782,  1341,   403,   253, 13081, 45813, 20158,\n",
       "           326, 31690,  4103,  1048, 13849,   281,  1089,   616,  2303, 41382,\n",
       "          4830,   534,   597, 16384,  3746,   281,   830,   253, 22831, 16203,\n",
       "           249, 30334,   313, 27415,  2284,   285, 11418,    13,  6752,   481,\n",
       "           187,  6560,   321,  2814,  8424,  1341, 31690,   689,  1048, 13849,\n",
       "           275,  2380,   281,  4975,   313,    42,  2225,  6836,  1162,   355,\n",
       "           904,  6157,    10,   285,   597, 31690,   432,  2173,  8424,    14,\n",
       "          3992,  8593,   313,    70,    15,    72,   904, 26382,   285,   749,\n",
       "          2254, 13267,  8232,    10,   281,   643,  4811,   313,  2019,   274,\n",
       "           413,    13,  6469,   481,   187,  8983,    14,  2225,  3875,    13,\n",
       "           533,  1327,    14, 19623,  4215,  8512,   452,   644,  2011,   281,\n",
       "         31690,   275,   253,  6782,  3998,   275,  6773,   313, 22384,  1162,\n",
       "           355,   904,  4050,   582,   285,   275, 25045,   285,  1327,    14,\n",
       "         13961, 47063,   347,   973,   313,    52,  1403,  2960,  1162,   355,\n",
       "           904,  4332,   481,   187,  3650, 19143,    13, 42782,  1341,    13,\n",
       "          8424,  1341,   285,  8512,   671, 31690,  1309, 24022,  2440,    15,\n",
       "          5595, 19836,    13,  1501,    14,  2225,  3875,  8512, 33781,   281,\n",
       "         19145, 10844,  3470,   452,   281, 31690,   689,  4942,  1048, 13849,\n",
       "           432,   253, 11454, 30402,   281,   616,  2303,  8593,   313,  6560,\n",
       "          1822, 21559,    13,   374,  2109,  1407,    13,  3532,   321,  2814,\n",
       "         49063,   481, 50279]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1]]), 'labels': tensor([[ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,   510,  1953,   310,  4942,  3862,   285,   581,   943,\n",
       "          1379,   715,  2395,   326,   253,  3998,   417,   760,  8414,   273,\n",
       "          8512,    13,   533,   671, 42782,  1341,   313, 13821,   422,  1341,\n",
       "            10,   285,   638,    14,  2225,  3875, 16069,  8424,  1341,    15,\n",
       "          5488,    13,   347,  4619,  7715,    14, 30202,  1346,   452,  4860,\n",
       "            13, 16743,  3924,   310,  1077,  1774,    13,   347,   253,  6684,\n",
       "         24022,  3998,   310,  1077,  1027,   432,   253,  6782,  3998,    15,\n",
       "           187,  6436,    13,   846,   256, 12545,   949,  2710, 16516,    13,\n",
       "           253,  3662,   281,   253,  1953,   310,  2686, 24678,  2969,    27,\n",
       "          6279,    13,  3998,  1341, 31690,    15,   187,   688, 50276,   783,\n",
       "          6782,  3998, 42782,  1341, 31690,   275,   253,  3998,   313,    44,\n",
       "         42824,  1814,    85,    13,  4748,   481,  4051,   451,  1341,   403,\n",
       "          3206,   275,   247, 35988,   273,  3470,    13,   533,   247, 16613,\n",
       "          1650,   273, 46447, 42782,  1341,   403,   253, 13081, 45813, 20158,\n",
       "           326, 31690,  4103,  1048, 13849,   281,  1089,   616,  2303, 41382,\n",
       "          4830,   534,   597, 16384,  3746,   281,   830,   253, 22831, 16203,\n",
       "           249, 30334,   313, 27415,  2284,   285, 11418,    13,  6752,   481,\n",
       "           187,  6560,   321,  2814,  8424,  1341, 31690,   689,  1048, 13849,\n",
       "           275,  2380,   281,  4975,   313,    42,  2225,  6836,  1162,   355,\n",
       "           904,  6157,    10,   285,   597, 31690,   432,  2173,  8424,    14,\n",
       "          3992,  8593,   313,    70,    15,    72,   904, 26382,   285,   749,\n",
       "          2254, 13267,  8232,    10,   281,   643,  4811,   313,  2019,   274,\n",
       "           413,    13,  6469,   481,   187,  8983,    14,  2225,  3875,    13,\n",
       "           533,  1327,    14, 19623,  4215,  8512,   452,   644,  2011,   281,\n",
       "         31690,   275,   253,  6782,  3998,   275,  6773,   313, 22384,  1162,\n",
       "           355,   904,  4050,   582,   285,   275, 25045,   285,  1327,    14,\n",
       "         13961, 47063,   347,   973,   313,    52,  1403,  2960,  1162,   355,\n",
       "           904,  4332,   481,   187,  3650, 19143,    13, 42782,  1341,    13,\n",
       "          8424,  1341,   285,  8512,   671, 31690,  1309, 24022,  2440,    15,\n",
       "          5595, 19836,    13,  1501,    14,  2225,  3875,  8512, 33781,   281,\n",
       "         19145, 10844,  3470,   452,   281, 31690,   689,  4942,  1048, 13849,\n",
       "           432,   253, 11454, 30402,   281,   616,  2303,  8593,   313,  6560,\n",
       "          1822, 21559,    13,   374,  2109,  1407,    13,  3532,   321,  2814,\n",
       "         49063,   481, 50279]])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T12:08:20.287235Z",
     "start_time": "2024-09-06T12:08:20.285131Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# todo: investigate how olmo uses a single training iteration, check masking\n",
    "# todo: add filtering with regard to open instruct (threshold for similarity)\n",
    "# todo: ranking between sampling\n",
    "# todo: tf-idf -> term-frequency inverse-document-frequency\n",
    "# todo: think about explainability vs. similarity"
   ],
   "id": "e1ce277adef4a061",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# random projections to reduce weight vector size\n",
    "# compare ranking to other algorithms: bm25, tf-idf, (rouge optionally)"
   ],
   "id": "f1b0b36aa660f94e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
