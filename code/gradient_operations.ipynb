{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T21:03:23.706148Z",
     "start_time": "2024-11-07T21:03:23.688586Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# google colab related stuff\n",
    "def is_running_on_colab():\n",
    "    try:\n",
    "        import google.colab\n",
    "        return True\n",
    "    except ImportError:\n",
    "        return False\n",
    "\n",
    "if is_running_on_colab():\n",
    "    import os\n",
    "    os.chdir(\"/content\")\n",
    "    !git clone https://github.com/lukas-hinterleitner/master-thesis.git\n",
    "    \n",
    "    os.chdir(\"/content/master-thesis\")\n",
    "    !git submodule init\n",
    "    !git submodule update\n",
    "    \n",
    "    !pip uninstall ibis-framework torchvision torchaudio -y\n",
    "    !pip install -r requirements.txt\n",
    "    os.kill(os.getpid(), 9)"
   ],
   "id": "80ad9f31be3b471e",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T21:03:24.100364Z",
     "start_time": "2024-11-07T21:03:24.092414Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# google colab related stuff\n",
    "if is_running_on_colab():\n",
    "    import os\n",
    "    os.chdir(\"/content/master-thesis/code\")"
   ],
   "id": "829271f117d99062",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-07T21:03:41.312235Z",
     "start_time": "2024-11-07T21:03:24.470071Z"
    }
   },
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_from_disk\n",
    "\n",
    "from config import hf_model_id, lima_filtered_paraphrased_dataset_path, get_dataset_config\n",
    "from torch.utils.data import Subset\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import gc\n",
    "\n",
    "from utilities.preprocessing import prepare_dataset\n",
    "from utilities.gradient_operations import get_gradients, get_flattened_weight_vector"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-07 22:03:37,330] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:gcc -pthread -B /home/lukashinterleitner/anaconda3/envs/master-thesis/compiler_compat -fno-strict-overflow -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /home/lukashinterleitner/anaconda3/envs/master-thesis/include -fPIC -O2 -isystem /home/lukashinterleitner/anaconda3/envs/master-thesis/include -fPIC -c /tmp/tmp52v2k_a5/test.c -o /tmp/tmp52v2k_a5/test.o\n",
      "INFO:root:gcc -pthread -B /home/lukashinterleitner/anaconda3/envs/master-thesis/compiler_compat /tmp/tmp52v2k_a5/test.o -laio -o /tmp/tmp52v2k_a5/a.out\n",
      "/home/lukashinterleitner/anaconda3/envs/master-thesis/compiler_compat/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "INFO:root:gcc -pthread -B /home/lukashinterleitner/anaconda3/envs/master-thesis/compiler_compat -fno-strict-overflow -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /home/lukashinterleitner/anaconda3/envs/master-thesis/include -fPIC -O2 -isystem /home/lukashinterleitner/anaconda3/envs/master-thesis/include -fPIC -c /tmp/tmpiw859gct/test.c -o /tmp/tmpiw859gct/test.o\n",
      "INFO:root:gcc -pthread -B /home/lukashinterleitner/anaconda3/envs/master-thesis/compiler_compat /tmp/tmpiw859gct/test.o -L/usr -L/usr/lib64 -lcufile -o /tmp/tmpiw859gct/a.out\n",
      "/home/lukashinterleitner/anaconda3/envs/master-thesis/compiler_compat/ld: cannot find -lcufile: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T21:03:41.336551Z",
     "start_time": "2024-11-07T21:03:41.322856Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ],
   "id": "af748f64e20a4fa8",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T21:03:41.792773Z",
     "start_time": "2024-11-07T21:03:41.400340Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ],
   "id": "cdeb08b4f6d2957",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T21:03:42.797954Z",
     "start_time": "2024-11-07T21:03:41.872152Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(hf_model_id)\n",
    "tokenizer = AutoTokenizer.from_pretrained(hf_model_id)\n",
    "\n",
    "print(tokenizer.eos_token_id)\n",
    "print(tokenizer.pad_token_id)"
   ],
   "id": "addc6245190d0ee2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50279\n",
      "1\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T21:03:42.889532Z",
     "start_time": "2024-11-07T21:03:42.878294Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset_config = get_dataset_config(model)\n",
    "dataset_config"
   ],
   "id": "2a785ac31470274e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetConfig(chat_template='tulu', preference_chosen_key='chosen', preference_rejected_key='rejected', sft_messages_key='messages', binary_messages_key='messages', label='binary_labels', convert_preference_to_binary_dataset=False, max_token_length=2048, max_prompt_token_length=None, sanity_check=False, sanity_check_max_samples=100, batched=False, load_from_cache_file=True, num_proc=12, train_only_on_prompt=True, ncols=2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T21:03:42.993833Z",
     "start_time": "2024-11-07T21:03:42.983273Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ],
   "id": "c64e2b22c156b3f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T21:03:43.106763Z",
     "start_time": "2024-11-07T21:03:43.098209Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# remove the comment from the following line, if the model should be processed on a GPU\n",
    "# model.to(device)"
   ],
   "id": "f46f61e1b7ba1240",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T21:03:43.193533Z",
     "start_time": "2024-11-07T21:03:43.177223Z"
    }
   },
   "cell_type": "code",
   "source": "model.eval()",
   "id": "1b5ea9b4364e38c2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OlmoForCausalLM(\n",
       "  (model): OlmoModel(\n",
       "    (embed_tokens): Embedding(50304, 2048, padding_idx=1)\n",
       "    (layers): ModuleList(\n",
       "      (0-15): 16 x OlmoDecoderLayer(\n",
       "        (self_attn): OlmoSdpaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): OlmoRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): OlmoMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): OlmoLayerNorm()\n",
       "        (post_attention_layernorm): OlmoLayerNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): OlmoLayerNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=50304, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T21:03:43.300267Z",
     "start_time": "2024-11-07T21:03:43.275280Z"
    }
   },
   "cell_type": "code",
   "source": "dataset = load_from_disk(lima_filtered_paraphrased_dataset_path)",
   "id": "b94aff18b2d7ddec",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T21:03:43.391549Z",
     "start_time": "2024-11-07T21:03:43.378746Z"
    }
   },
   "cell_type": "code",
   "source": "dataset.column_names",
   "id": "3eb3e15ea55c0ab1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id', 'messages', 'paraphrased_messages']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T21:03:43.518013Z",
     "start_time": "2024-11-07T21:03:43.501567Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create two datasets for original messages and paraphrased messages\n",
    "\n",
    "original_dataset_columns = [\"id\", \"messages\"]\n",
    "paraphrased_dataset_columns = [\"id\", \"paraphrased_messages\"]\n",
    "\n",
    "original_dataset = dataset.select_columns(original_dataset_columns)\n",
    "paraphrased_dataset = dataset.select_columns(paraphrased_dataset_columns)"
   ],
   "id": "80d113df7deefae7",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T21:03:43.583708Z",
     "start_time": "2024-11-07T21:03:43.576062Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(original_dataset.column_names)\n",
    "print(paraphrased_dataset_columns)"
   ],
   "id": "c9130c45e5829b44",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'messages']\n",
      "['id', 'paraphrased_messages']\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T21:03:43.742541Z",
     "start_time": "2024-11-07T21:03:43.730696Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# rename paraphrased messages to messages since open-instruct encode_sft_example only works with 'messages'key\n",
    "paraphrased_dataset = paraphrased_dataset.rename_column(\"paraphrased_messages\", \"messages\")"
   ],
   "id": "e52b95d5fd142f69",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T21:03:43.824478Z",
     "start_time": "2024-11-07T21:03:43.812877Z"
    }
   },
   "cell_type": "code",
   "source": "original_dataset",
   "id": "45c7b281507a435b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'messages'],\n",
       "    num_rows: 988\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T21:03:44.102164Z",
     "start_time": "2024-11-07T21:03:44.093164Z"
    }
   },
   "cell_type": "code",
   "source": "paraphrased_dataset",
   "id": "37fbaaaf4b0f9c40",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'messages'],\n",
       "    num_rows: 988\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T21:03:44.330856Z",
     "start_time": "2024-11-07T21:03:44.324354Z"
    }
   },
   "cell_type": "code",
   "source": "sample_size = 5",
   "id": "3ff7d92d88aef19e",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T21:03:44.898124Z",
     "start_time": "2024-11-07T21:03:44.618115Z"
    }
   },
   "cell_type": "code",
   "source": "original_dataset_tokenized = prepare_dataset(dataset=dataset, tokenizer=tokenizer, model=model, sample_size=sample_size)",
   "id": "7f41a2fe2aa324e8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tokenizing and reformatting instruction data:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b7d9ebc6bc894abc9213230d28df4216"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T21:04:25.608881Z",
     "start_time": "2024-11-07T21:04:25.292148Z"
    }
   },
   "cell_type": "code",
   "source": "paraphrased_dataset_tokenized = prepare_dataset(dataset=paraphrased_dataset, tokenizer=tokenizer, model=model, sample_size=sample_size)",
   "id": "b052b67bbef85bd1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tokenizing and reformatting instruction data:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a645722168c64aaf92ec214ca627e629"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Filter:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "82708e76edd44ca5bdaa6d07ebc78d07"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T21:05:48.572724Z",
     "start_time": "2024-11-07T21:05:48.441361Z"
    }
   },
   "cell_type": "code",
   "source": [
    "gradients = dict()\n",
    "\n",
    "for original in original_dataset_tokenized:\n",
    "    original_id = original[\"id\"][0][0]\n",
    "    \n",
    "    original_gradients = get_gradients(model, original)\n",
    "    original_flattened_gradients = get_flattened_weight_vector(gradients)#.to(device)\n",
    "    \n",
    "    for paraphrased in paraphrased_dataset_tokenized:\n",
    "        paraphrased_id = paraphrased[\"id\"][0][0]\n",
    "        \n",
    "        paraphrased_gradients = get_gradients(model, paraphrased)\n",
    "        paraphrased_flattened_gradients = get_flattened_weight_vector(paraphrased_gradients)#.to(device)\n",
    "        \n",
    "        gradients[(original_id, paraphrased_id)] = original_flattened_gradients.dot(paraphrased_flattened_gradients)"
   ],
   "id": "a0577aca6eaee9a7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lukashinterleitner/anaconda3/envs/master-thesis/lib/python3.12/site-packages/transformers/data/data_collator.py:656: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
      "  batch[\"labels\"] = torch.tensor(batch[\"labels\"], dtype=torch.int64)\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T21:06:14.474692Z",
     "start_time": "2024-11-07T21:06:14.459918Z"
    }
   },
   "cell_type": "code",
   "source": "gradients",
   "id": "645933176121d9fd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('lima_0', 'lima_0'): 0,\n",
       " ('lima_0', 'lima_1'): 0,\n",
       " ('lima_0', 'lima_2'): 0,\n",
       " ('lima_0', 'lima_3'): 0,\n",
       " ('lima_0', 'lima_4'): 0,\n",
       " ('lima_1', 'lima_0'): 0,\n",
       " ('lima_1', 'lima_1'): 0,\n",
       " ('lima_1', 'lima_2'): 0,\n",
       " ('lima_1', 'lima_3'): 0,\n",
       " ('lima_1', 'lima_4'): 0,\n",
       " ('lima_2', 'lima_0'): 0,\n",
       " ('lima_2', 'lima_1'): 0,\n",
       " ('lima_2', 'lima_2'): 0,\n",
       " ('lima_2', 'lima_3'): 0,\n",
       " ('lima_2', 'lima_4'): 0,\n",
       " ('lima_3', 'lima_0'): 0,\n",
       " ('lima_3', 'lima_1'): 0,\n",
       " ('lima_3', 'lima_2'): 0,\n",
       " ('lima_3', 'lima_3'): 0,\n",
       " ('lima_3', 'lima_4'): 0,\n",
       " ('lima_4', 'lima_0'): 0,\n",
       " ('lima_4', 'lima_1'): 0,\n",
       " ('lima_4', 'lima_2'): 0,\n",
       " ('lima_4', 'lima_3'): 0,\n",
       " ('lima_4', 'lima_4'): 0}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T11:05:32.927284Z",
     "start_time": "2024-11-06T11:05:32.917267Z"
    }
   },
   "cell_type": "code",
   "source": "#flattened_gradients.size()",
   "id": "b531332c6bc28f41",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1176764416])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T11:05:33.051204Z",
     "start_time": "2024-11-06T11:05:33.044899Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# todo: investigate how olmo uses a single training iteration, check masking\n",
    "# todo: add filtering with regard to open instruct (threshold for similarity)\n",
    "# todo: ranking between sampling\n",
    "# todo: tf-idf -> term-frequency inverse-document-frequency\n",
    "# todo: think about explainability vs. similarity"
   ],
   "id": "e1ce277adef4a061",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T11:05:33.120900Z",
     "start_time": "2024-11-06T11:05:33.114491Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# random projections to reduce weight vector size\n",
    "# compare ranking to other algorithms: bm25, tf-idf, (rouge optionally)"
   ],
   "id": "f1b0b36aa660f94e",
   "outputs": [],
   "execution_count": 17
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
