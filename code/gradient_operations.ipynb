{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-06T06:50:44.769241Z",
     "start_time": "2024-09-06T06:50:44.729359Z"
    }
   },
   "source": [
    "from torch.nn.functional import cosine_similarity\n",
    "from transformers import OlmoForCausalLM, AutoTokenizer\n",
    "from datasets import load_from_disk\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from utilities import prepare_dataset"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'open_instruct.model_utils'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 8\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mrandom\u001B[39;00m\n\u001B[0;32m----> 8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mutilities\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m prepare_dataset\n",
      "File \u001B[0;32m~/Documents/Master_Data_Science/Master_Thesis/code/utilities.py:8\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DataLoader\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtransformers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m PreTrainedTokenizerFast, DataCollatorForSeq2Seq, PreTrainedModel, PreTrainedTokenizerBase\n\u001B[0;32m----> 8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mopen_instruct\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mopen_instruct\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfinetune\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m encode_with_messages_format\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mprint_red\u001B[39m(skk):\n\u001B[1;32m     12\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\033\u001B[39;00m\u001B[38;5;124m[91m \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;130;01m\\033\u001B[39;00m\u001B[38;5;124m[00m\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(skk))\n",
      "File \u001B[0;32m~/Documents/Master_Data_Science/Master_Thesis/code/open_instruct/open_instruct/finetune.py:55\u001B[0m\n\u001B[1;32m     54\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mencode_with_prompt_completion_format\u001B[39m(example, tokenizer, max_seq_length, add_bos\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[0;32m---> 55\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     56\u001B[0m \u001B[38;5;124;03m    Here we assume each example has 'prompt' and 'completion' fields.\u001B[39;00m\n\u001B[1;32m     57\u001B[0m \u001B[38;5;124;03m    We concatenate prompt and completion and tokenize them together because otherwise prompt will be padded/trancated\u001B[39;00m\n\u001B[1;32m     58\u001B[0m \u001B[38;5;124;03m    and it doesn't make sense to follow directly with the completion.\u001B[39;00m\n\u001B[1;32m     59\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m     60\u001B[0m     \u001B[38;5;66;03m# if prompt doesn't end with space and completion doesn't start with space, add space\u001B[39;00m\n\u001B[1;32m     61\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m example[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprompt\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mendswith((\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m example[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcompletion\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mstartswith((\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)):\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'open_instruct.model_utils'"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T16:39:50.698206Z",
     "start_time": "2024-09-05T16:39:50.686174Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ],
   "id": "af748f64e20a4fa8",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T16:40:03.895440Z",
     "start_time": "2024-09-05T16:39:51.575082Z"
    }
   },
   "cell_type": "code",
   "source": [
    "olmo = OlmoForCausalLM.from_pretrained(\"allenai/OLMo-1B-hf\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"allenai/OLMo-1B-hf\")\n",
    "\n",
    "print(tokenizer.eos_token_id)\n",
    "print(tokenizer.pad_token_id)"
   ],
   "id": "addc6245190d0ee2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50279\n",
      "1\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T16:40:04.109625Z",
     "start_time": "2024-09-05T16:40:04.076729Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ],
   "id": "c64e2b22c156b3f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T16:40:04.794870Z",
     "start_time": "2024-09-05T16:40:04.770482Z"
    }
   },
   "cell_type": "code",
   "source": "olmo.eval()",
   "id": "1b5ea9b4364e38c2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OlmoForCausalLM(\n",
       "  (model): OlmoModel(\n",
       "    (embed_tokens): Embedding(50304, 2048, padding_idx=1)\n",
       "    (layers): ModuleList(\n",
       "      (0-15): 16 x OlmoDecoderLayer(\n",
       "        (self_attn): OlmoSdpaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): OlmoRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): OlmoMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): OlmoLayerNorm()\n",
       "        (post_attention_layernorm): OlmoLayerNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): OlmoLayerNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=50304, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T16:40:05.205341Z",
     "start_time": "2024-09-05T16:40:05.158875Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = load_from_disk(\"./data/lima/single_question_answers\")\n",
    "dataset"
   ],
   "id": "b94aff18b2d7ddec",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['dataset', 'id', 'messages'],\n",
       "    num_rows: 988\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T16:40:05.675490Z",
     "start_time": "2024-09-05T16:40:05.561918Z"
    }
   },
   "cell_type": "code",
   "source": "dataset[\"messages\"][0][0][\"content\"]",
   "id": "386490549705eab1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Can brain cells move? By movement I mean long distance migration (preferably within the brain only).'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T16:40:06.893978Z",
     "start_time": "2024-09-05T16:40:06.808824Z"
    }
   },
   "cell_type": "code",
   "source": "dataset[\"messages\"][0][1][\"content\"]",
   "id": "c641fcd39cc1439b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The question is relatively broad and one should take into account that the brain not only consists of neurons, but also glial cells (supportive cells) and pre-mitotic neuronal stem cells. Furthermore, as critical fellow-scientists have indicated, developmental stage is very important, as the developing embryonic brain is very different from the adult brain.\\nHowever, after sifting through various publications, the answer to the question is actually remarkably simple: Yes, brain cells migrate.\\nIn  the adult brain glial cells migrate in the brain (Klämbt, 2009). Glial cells are involved in a myriad of functions, but a notable example of migrating glial cells are the oligodendrocytes that migrate relative long distances to find their target axons onto which they wrap themselves to form the insulating myelin sheath (Tsai and Miller, 2002).\\nNeuronal stem cells migrate over long distances in response to injury (Imitola et al., 2004) and they migrate from specific stem-cell locations (e.g., hippocampus and subventricular zone) to other regions (Clarke, 2003).\\nPost-mitotic, but non-differentiated neurons have been shown to migrate in the adult brain in fish (Scott et al., 2012), and in mammals and non-human primates as well (Sawada et al., 2011).\\nNot surprisingly, glial cells, stem cells and neurons also migrate during embryonic development. Most notably, post-mitotic neurons destined to fulfill peripheral functions have to migrate over relatively long distances from the neural crest to their target locations (Neuroscience, 2nd ed, Neuronal Migration).'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T16:40:22.545495Z",
     "start_time": "2024-09-05T16:40:08.096027Z"
    }
   },
   "cell_type": "code",
   "source": "train_dataloader = prepare_dataset(dataset=dataset, model=olmo, tokenizer=tokenizer)",
   "id": "7f41a2fe2aa324e8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tokenizing and reformatting instruction data:   0%|          | 0/988 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "27db41adb66148bc8a3fa731f6d56a41"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T16:40:22.625051Z",
     "start_time": "2024-09-05T16:40:22.615661Z"
    }
   },
   "cell_type": "code",
   "source": "print(len(train_dataloader))",
   "id": "183611490872b818",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "988\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T16:40:22.861099Z",
     "start_time": "2024-09-05T16:40:22.850631Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_gradients(batch):\n",
    "    gradients = {}\n",
    "    \n",
    "    olmo.zero_grad()\n",
    "\n",
    "    output = olmo(**batch, use_cache=False)\n",
    "    loss = output.loss\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    for name, param in olmo.named_parameters():\n",
    "        if param.grad is not None:\n",
    "            gradients[name] = param.grad.clone().detach()\n",
    "            \n",
    "    return gradients"
   ],
   "id": "df0e00edc0cb34a0",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T16:40:26.817953Z",
     "start_time": "2024-09-05T16:40:23.336881Z"
    }
   },
   "cell_type": "code",
   "source": [
    "decoded_input = tokenizer.decode(token_ids=list(train_dataloader)[0][\"input_ids\"][0].tolist())\n",
    "decoded_input"
   ],
   "id": "209d4c46ee109386",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|user|>\\nCan brain cells move? By movement I mean long distance migration (preferably within the brain only).\\n<|assistant|>\\nThe question is relatively broad and one should take into account that the brain not only consists of neurons, but also glial cells (supportive cells) and pre-mitotic neuronal stem cells. Furthermore, as critical fellow-scientists have indicated, developmental stage is very important, as the developing embryonic brain is very different from the adult brain.\\nHowever, after sifting through various publications, the answer to the question is actually remarkably simple: Yes, brain cells migrate.\\nIn  the adult brain glial cells migrate in the brain (Klämbt, 2009). Glial cells are involved in a myriad of functions, but a notable example of migrating glial cells are the oligodendrocytes that migrate relative long distances to find their target axons onto which they wrap themselves to form the insulating myelin sheath (Tsai and Miller, 2002).\\nNeuronal stem cells migrate over long distances in response to injury (Imitola et al., 2004) and they migrate from specific stem-cell locations (e.g., hippocampus and subventricular zone) to other regions (Clarke, 2003).\\nPost-mitotic, but non-differentiated neurons have been shown to migrate in the adult brain in fish (Scott et al., 2012), and in mammals and non-human primates as well (Sawada et al., 2011).\\nNot surprisingly, glial cells, stem cells and neurons also migrate during embryonic development. Most notably, post-mitotic neurons destined to fulfill peripheral functions have to migrate over relatively long distances from the neural crest to their target locations (Neuroscience, 2nd ed, Neuronal Migration).<|endoftext|>'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T16:40:29.833858Z",
     "start_time": "2024-09-05T16:40:26.921235Z"
    }
   },
   "cell_type": "code",
   "source": [
    "decoded_output = tokenizer.decode(token_ids=[(tokenizer.pad_token_id if token == -100 else token) for token in list(train_dataloader)[0][\"labels\"][0].tolist()])\n",
    "decoded_output"
   ],
   "id": "fe368e39bf970b52",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|padding|><|padding|><|padding|><|padding|><|padding|><|padding|><|padding|><|padding|><|padding|><|padding|><|padding|><|padding|><|padding|><|padding|><|padding|><|padding|><|padding|><|padding|><|padding|><|padding|><|padding|><|padding|><|padding|><|padding|><|padding|><|padding|><|padding|><|padding|><|padding|><|padding|><|padding|><|padding|>The question is relatively broad and one should take into account that the brain not only consists of neurons, but also glial cells (supportive cells) and pre-mitotic neuronal stem cells. Furthermore, as critical fellow-scientists have indicated, developmental stage is very important, as the developing embryonic brain is very different from the adult brain.\\nHowever, after sifting through various publications, the answer to the question is actually remarkably simple: Yes, brain cells migrate.\\nIn  the adult brain glial cells migrate in the brain (Klämbt, 2009). Glial cells are involved in a myriad of functions, but a notable example of migrating glial cells are the oligodendrocytes that migrate relative long distances to find their target axons onto which they wrap themselves to form the insulating myelin sheath (Tsai and Miller, 2002).\\nNeuronal stem cells migrate over long distances in response to injury (Imitola et al., 2004) and they migrate from specific stem-cell locations (e.g., hippocampus and subventricular zone) to other regions (Clarke, 2003).\\nPost-mitotic, but non-differentiated neurons have been shown to migrate in the adult brain in fish (Scott et al., 2012), and in mammals and non-human primates as well (Sawada et al., 2011).\\nNot surprisingly, glial cells, stem cells and neurons also migrate during embryonic development. Most notably, post-mitotic neurons destined to fulfill peripheral functions have to migrate over relatively long distances from the neural crest to their target locations (Neuroscience, 2nd ed, Neuronal Migration).<|endoftext|>'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# gradient checking - start"
   ],
   "id": "4dfb3fde0ab357c6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T16:40:36.413048Z",
     "start_time": "2024-09-05T16:40:29.958Z"
    }
   },
   "cell_type": "code",
   "source": [
    "training_sample_0 = list(train_dataloader)[0]\n",
    "training_sample_1 = list(train_dataloader)[1]"
   ],
   "id": "f193e6d05c62d392",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T16:40:36.462273Z",
     "start_time": "2024-09-05T16:40:36.452300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# first and foremost, check if two samples are different after tokenizing\n",
    "if training_sample_0[\"input_ids\"].equal(training_sample_1[\"input_ids\"]): \n",
    "    print(\"Tokenized inputs are the same. Check tokenizing functionality!\")\n",
    "else:\n",
    "    print(\"As expected, tokenized inputs are not the same. \")"
   ],
   "id": "4c2ff3d1240b9851",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As expected, tokenized inputs are not the same. \n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# check idempotency of some input samples\n",
    "gradients_sample_0 = get_gradients(training_sample_0)\n",
    "gradients_sample_1 = get_gradients(training_sample_1)\n",
    "gradients_sample_0_later = get_gradients(training_sample_0)"
   ],
   "id": "521092b0fb49e785",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T16:42:37.206146Z",
     "start_time": "2024-09-05T16:42:37.203343Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# gradient dictionary keys of sample_0, sample_0_later and sample_1 should be the same\n",
    "assert gradients_sample_0.keys() == gradients_sample_0_later.keys() == gradients_sample_1.keys()"
   ],
   "id": "254dce7901dc59cb",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T16:42:39.183378Z",
     "start_time": "2024-09-05T16:42:38.840711Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# compare gradient of the same sample\n",
    "assert gradients_sample_0.keys() == gradients_sample_0_later.keys(), \"Gradient dictionaries must have same keys.\"\n",
    "\n",
    "for key in gradients_sample_0.keys():\n",
    "    assert gradients_sample_0[key].equal(gradients_sample_0_later[key]), f\"Gradient '{key}' not equal!\"\n",
    "    \n",
    "print(\"Gradients are equal when using the same sample.\")"
   ],
   "id": "baa639c8c85aacc4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradients are equal when using the same sample.\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T16:42:39.791938Z",
     "start_time": "2024-09-05T16:42:39.788497Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# compare gradients of two different samples\n",
    "assert gradients_sample_0.keys() == gradients_sample_1.keys(), \"Gradient dictionaries must have same keys.\"\n",
    "\n",
    "for key in gradients_sample_0.keys():\n",
    "    assert not gradients_sample_0[key].equal(gradients_sample_1[key]), f\"Gradient '{key}' equal!\"\n",
    "    \n",
    "print(\"Gradients are different when using two different samples.\")"
   ],
   "id": "eb72be828f96a0a8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradients are different when using two different samples.\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T18:01:43.261545Z",
     "start_time": "2024-09-05T18:01:43.258588Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_flattened_weight_vector(weight_dict: dict) -> torch.Tensor:\n",
    "    flattened_weights = []\n",
    "    for weights in weight_dict.values():\n",
    "        flattened_weights.append(weights.flatten())\n",
    "        \n",
    "    return torch.cat(flattened_weights)"
   ],
   "id": "59be41d86eae8fe5",
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T18:07:06.779077Z",
     "start_time": "2024-09-05T18:07:04.787539Z"
    }
   },
   "cell_type": "code",
   "source": "get_flattened_weight_vector(gradients_sample_0)",
   "id": "fb17cd09c8dd2e9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-6.6105e-09,  2.3362e-09, -6.1912e-09,  ..., -2.1295e-04,\n",
       "         1.4201e-03, -1.9168e-03])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T18:06:27.453623Z",
     "start_time": "2024-09-05T18:06:11.370434Z"
    }
   },
   "cell_type": "code",
   "source": "cosine_similarity(get_flattened_weight_vector(gradients_sample_0), get_flattened_weight_vector(gradients_sample_0), dim=0)",
   "id": "c831a27d690ea686",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.2433)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 72
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T06:52:42.145098Z",
     "start_time": "2024-09-04T06:52:41.367450Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#del training_sample_0\n",
    "#del training_sample_1\n",
    "\n",
    "#del gradients_sample_0\n",
    "#del gradients_sample_1\n",
    "#del gradients_sample_0_later"
   ],
   "id": "de642344a925136f",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# gradient checking - end\n",
    "\n",
    "---"
   ],
   "id": "c3eae9e9703e1bbc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T12:07:33.184277Z",
     "start_time": "2024-09-04T12:07:02.301136Z"
    }
   },
   "cell_type": "code",
   "source": [
    "training_sample_0 = list(train_dataloader)[0]\n",
    "\n",
    "gradients_sample_0 = get_gradients(training_sample_0)"
   ],
   "id": "5e53c8a11abe6c32",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T12:12:47.971572Z",
     "start_time": "2024-09-04T12:12:47.960419Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for key, value in gradients_sample_0.items():\n",
    "    \n",
    "    print(f\"{key}: {value.shape}\")"
   ],
   "id": "bc244fa7d6650e8b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.embed_tokens.weight: torch.Size([50304, 2048])\n",
      "model.layers.0.self_attn.q_proj.weight: torch.Size([2048, 2048])\n",
      "model.layers.0.self_attn.k_proj.weight: torch.Size([2048, 2048])\n",
      "model.layers.0.self_attn.v_proj.weight: torch.Size([2048, 2048])\n",
      "model.layers.0.self_attn.o_proj.weight: torch.Size([2048, 2048])\n",
      "model.layers.0.mlp.gate_proj.weight: torch.Size([8192, 2048])\n",
      "model.layers.0.mlp.up_proj.weight: torch.Size([8192, 2048])\n",
      "model.layers.0.mlp.down_proj.weight: torch.Size([2048, 8192])\n",
      "model.layers.1.self_attn.q_proj.weight: torch.Size([2048, 2048])\n",
      "model.layers.1.self_attn.k_proj.weight: torch.Size([2048, 2048])\n",
      "model.layers.1.self_attn.v_proj.weight: torch.Size([2048, 2048])\n",
      "model.layers.1.self_attn.o_proj.weight: torch.Size([2048, 2048])\n",
      "model.layers.1.mlp.gate_proj.weight: torch.Size([8192, 2048])\n",
      "model.layers.1.mlp.up_proj.weight: torch.Size([8192, 2048])\n",
      "model.layers.1.mlp.down_proj.weight: torch.Size([2048, 8192])\n",
      "model.layers.2.self_attn.q_proj.weight: torch.Size([2048, 2048])\n",
      "model.layers.2.self_attn.k_proj.weight: torch.Size([2048, 2048])\n",
      "model.layers.2.self_attn.v_proj.weight: torch.Size([2048, 2048])\n",
      "model.layers.2.self_attn.o_proj.weight: torch.Size([2048, 2048])\n",
      "model.layers.2.mlp.gate_proj.weight: torch.Size([8192, 2048])\n",
      "model.layers.2.mlp.up_proj.weight: torch.Size([8192, 2048])\n",
      "model.layers.2.mlp.down_proj.weight: torch.Size([2048, 8192])\n",
      "model.layers.3.self_attn.q_proj.weight: torch.Size([2048, 2048])\n",
      "model.layers.3.self_attn.k_proj.weight: torch.Size([2048, 2048])\n",
      "model.layers.3.self_attn.v_proj.weight: torch.Size([2048, 2048])\n",
      "model.layers.3.self_attn.o_proj.weight: torch.Size([2048, 2048])\n",
      "model.layers.3.mlp.gate_proj.weight: torch.Size([8192, 2048])\n",
      "model.layers.3.mlp.up_proj.weight: torch.Size([8192, 2048])\n",
      "model.layers.3.mlp.down_proj.weight: torch.Size([2048, 8192])\n",
      "model.layers.4.self_attn.q_proj.weight: torch.Size([2048, 2048])\n",
      "model.layers.4.self_attn.k_proj.weight: torch.Size([2048, 2048])\n",
      "model.layers.4.self_attn.v_proj.weight: torch.Size([2048, 2048])\n",
      "model.layers.4.self_attn.o_proj.weight: torch.Size([2048, 2048])\n",
      "model.layers.4.mlp.gate_proj.weight: torch.Size([8192, 2048])\n",
      "model.layers.4.mlp.up_proj.weight: torch.Size([8192, 2048])\n",
      "model.layers.4.mlp.down_proj.weight: torch.Size([2048, 8192])\n",
      "model.layers.5.self_attn.q_proj.weight: torch.Size([2048, 2048])\n",
      "model.layers.5.self_attn.k_proj.weight: torch.Size([2048, 2048])\n",
      "model.layers.5.self_attn.v_proj.weight: torch.Size([2048, 2048])\n",
      "model.layers.5.self_attn.o_proj.weight: torch.Size([2048, 2048])\n",
      "model.layers.5.mlp.gate_proj.weight: torch.Size([8192, 2048])\n",
      "model.layers.5.mlp.up_proj.weight: torch.Size([8192, 2048])\n",
      "model.layers.5.mlp.down_proj.weight: torch.Size([2048, 8192])\n",
      "model.layers.6.self_attn.q_proj.weight: torch.Size([2048, 2048])\n",
      "model.layers.6.self_attn.k_proj.weight: torch.Size([2048, 2048])\n",
      "model.layers.6.self_attn.v_proj.weight: torch.Size([2048, 2048])\n",
      "model.layers.6.self_attn.o_proj.weight: torch.Size([2048, 2048])\n",
      "model.layers.6.mlp.gate_proj.weight: torch.Size([8192, 2048])\n",
      "model.layers.6.mlp.up_proj.weight: torch.Size([8192, 2048])\n",
      "model.layers.6.mlp.down_proj.weight: torch.Size([2048, 8192])\n",
      "model.layers.7.self_attn.q_proj.weight: torch.Size([2048, 2048])\n",
      "model.layers.7.self_attn.k_proj.weight: torch.Size([2048, 2048])\n",
      "model.layers.7.self_attn.v_proj.weight: torch.Size([2048, 2048])\n",
      "model.layers.7.self_attn.o_proj.weight: torch.Size([2048, 2048])\n",
      "model.layers.7.mlp.gate_proj.weight: torch.Size([8192, 2048])\n",
      "model.layers.7.mlp.up_proj.weight: torch.Size([8192, 2048])\n",
      "model.layers.7.mlp.down_proj.weight: torch.Size([2048, 8192])\n",
      "model.layers.8.self_attn.q_proj.weight: torch.Size([2048, 2048])\n",
      "model.layers.8.self_attn.k_proj.weight: torch.Size([2048, 2048])\n",
      "model.layers.8.self_attn.v_proj.weight: torch.Size([2048, 2048])\n",
      "model.layers.8.self_attn.o_proj.weight: torch.Size([2048, 2048])\n",
      "model.layers.8.mlp.gate_proj.weight: torch.Size([8192, 2048])\n",
      "model.layers.8.mlp.up_proj.weight: torch.Size([8192, 2048])\n",
      "model.layers.8.mlp.down_proj.weight: torch.Size([2048, 8192])\n",
      "model.layers.9.self_attn.q_proj.weight: torch.Size([2048, 2048])\n",
      "model.layers.9.self_attn.k_proj.weight: torch.Size([2048, 2048])\n",
      "model.layers.9.self_attn.v_proj.weight: torch.Size([2048, 2048])\n",
      "model.layers.9.self_attn.o_proj.weight: torch.Size([2048, 2048])\n",
      "model.layers.9.mlp.gate_proj.weight: torch.Size([8192, 2048])\n",
      "model.layers.9.mlp.up_proj.weight: torch.Size([8192, 2048])\n",
      "model.layers.9.mlp.down_proj.weight: torch.Size([2048, 8192])\n",
      "model.layers.10.self_attn.q_proj.weight: torch.Size([2048, 2048])\n",
      "model.layers.10.self_attn.k_proj.weight: torch.Size([2048, 2048])\n",
      "model.layers.10.self_attn.v_proj.weight: torch.Size([2048, 2048])\n",
      "model.layers.10.self_attn.o_proj.weight: torch.Size([2048, 2048])\n",
      "model.layers.10.mlp.gate_proj.weight: torch.Size([8192, 2048])\n",
      "model.layers.10.mlp.up_proj.weight: torch.Size([8192, 2048])\n",
      "model.layers.10.mlp.down_proj.weight: torch.Size([2048, 8192])\n",
      "model.layers.11.self_attn.q_proj.weight: torch.Size([2048, 2048])\n",
      "model.layers.11.self_attn.k_proj.weight: torch.Size([2048, 2048])\n",
      "model.layers.11.self_attn.v_proj.weight: torch.Size([2048, 2048])\n",
      "model.layers.11.self_attn.o_proj.weight: torch.Size([2048, 2048])\n",
      "model.layers.11.mlp.gate_proj.weight: torch.Size([8192, 2048])\n",
      "model.layers.11.mlp.up_proj.weight: torch.Size([8192, 2048])\n",
      "model.layers.11.mlp.down_proj.weight: torch.Size([2048, 8192])\n",
      "model.layers.12.self_attn.q_proj.weight: torch.Size([2048, 2048])\n",
      "model.layers.12.self_attn.k_proj.weight: torch.Size([2048, 2048])\n",
      "model.layers.12.self_attn.v_proj.weight: torch.Size([2048, 2048])\n",
      "model.layers.12.self_attn.o_proj.weight: torch.Size([2048, 2048])\n",
      "model.layers.12.mlp.gate_proj.weight: torch.Size([8192, 2048])\n",
      "model.layers.12.mlp.up_proj.weight: torch.Size([8192, 2048])\n",
      "model.layers.12.mlp.down_proj.weight: torch.Size([2048, 8192])\n",
      "model.layers.13.self_attn.q_proj.weight: torch.Size([2048, 2048])\n",
      "model.layers.13.self_attn.k_proj.weight: torch.Size([2048, 2048])\n",
      "model.layers.13.self_attn.v_proj.weight: torch.Size([2048, 2048])\n",
      "model.layers.13.self_attn.o_proj.weight: torch.Size([2048, 2048])\n",
      "model.layers.13.mlp.gate_proj.weight: torch.Size([8192, 2048])\n",
      "model.layers.13.mlp.up_proj.weight: torch.Size([8192, 2048])\n",
      "model.layers.13.mlp.down_proj.weight: torch.Size([2048, 8192])\n",
      "model.layers.14.self_attn.q_proj.weight: torch.Size([2048, 2048])\n",
      "model.layers.14.self_attn.k_proj.weight: torch.Size([2048, 2048])\n",
      "model.layers.14.self_attn.v_proj.weight: torch.Size([2048, 2048])\n",
      "model.layers.14.self_attn.o_proj.weight: torch.Size([2048, 2048])\n",
      "model.layers.14.mlp.gate_proj.weight: torch.Size([8192, 2048])\n",
      "model.layers.14.mlp.up_proj.weight: torch.Size([8192, 2048])\n",
      "model.layers.14.mlp.down_proj.weight: torch.Size([2048, 8192])\n",
      "model.layers.15.self_attn.q_proj.weight: torch.Size([2048, 2048])\n",
      "model.layers.15.self_attn.k_proj.weight: torch.Size([2048, 2048])\n",
      "model.layers.15.self_attn.v_proj.weight: torch.Size([2048, 2048])\n",
      "model.layers.15.self_attn.o_proj.weight: torch.Size([2048, 2048])\n",
      "model.layers.15.mlp.gate_proj.weight: torch.Size([8192, 2048])\n",
      "model.layers.15.mlp.up_proj.weight: torch.Size([8192, 2048])\n",
      "model.layers.15.mlp.down_proj.weight: torch.Size([2048, 8192])\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# todo: investigate how olmo uses a single training iteration, check masking\n",
    "# todo: add filtering with regard to open instruct (threshold for similarity)\n",
    "# todo: ranking between sampling\n",
    "# todo: tf-idf -> term-frequency inverse-document-frequency\n",
    "# todo: think about explainability vs. similarity"
   ],
   "id": "e1ce277adef4a061"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
