{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T09:17:25.121174Z",
     "start_time": "2024-11-08T09:17:25.103128Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from code.config import get_gradients_file_path\n",
    "\n",
    "\n",
    "# google colab related stuff\n",
    "def is_running_on_colab():\n",
    "    try:\n",
    "        import google.colab\n",
    "        return True\n",
    "    except ImportError:\n",
    "        return False\n",
    "    \n",
    "if is_running_on_colab():\n",
    "    import os\n",
    "    os.chdir(\"/content\")\n",
    "    !git clone https://github.com/lukas-hinterleitner/master-thesis.git\n",
    "    \n",
    "    os.chdir(\"/content/master-thesis\")\n",
    "    !git submodule init\n",
    "    !git submodule update\n",
    "    \n",
    "    !pip uninstall ibis-framework torchvision torchaudio -y\n",
    "    !pip install -r requirements.txt\n",
    "    os.kill(os.getpid(), 9)"
   ],
   "id": "80ad9f31be3b471e",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## !!! \n",
    "## Keep in mind, that the google colab session will crash after executing the above cell. This is necessary to load open-instruct as an editable package. Just continue by executing the next cell.\n",
    "## !!!"
   ],
   "id": "5a0b00095f9ef836"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T09:17:38.706040Z",
     "start_time": "2024-11-08T09:17:38.696205Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# google colab related stuff\n",
    "def is_running_on_colab():\n",
    "    try:\n",
    "        import google.colab\n",
    "        return True\n",
    "    except ImportError:\n",
    "        return False\n",
    "    \n",
    "if is_running_on_colab():\n",
    "    import os\n",
    "    os.chdir(\"/content/master-thesis/code\")\n",
    "    \n",
    "    from google.colab import output\n",
    "    output.enable_custom_widget_manager()"
   ],
   "id": "829271f117d99062",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-08T10:42:31.754995Z",
     "start_time": "2024-11-08T10:42:15.062120Z"
    }
   },
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_from_disk\n",
    "\n",
    "import torch\n",
    "import random\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from config import hf_model_id, lima_filtered_paraphrased_dataset_path, get_dataset_config, sample_size, get_gradients_file_path\n",
    "\n",
    "from utilities.preprocessing import prepare_dataset\n",
    "from utilities.gradient_operations import get_gradients, get_flattened_weight_vector"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-08 11:42:27,148] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:gcc -pthread -B /home/lukashinterleitner/anaconda3/envs/master-thesis/compiler_compat -fno-strict-overflow -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /home/lukashinterleitner/anaconda3/envs/master-thesis/include -fPIC -O2 -isystem /home/lukashinterleitner/anaconda3/envs/master-thesis/include -fPIC -c /tmp/tmp7jf800a9/test.c -o /tmp/tmp7jf800a9/test.o\n",
      "INFO:root:gcc -pthread -B /home/lukashinterleitner/anaconda3/envs/master-thesis/compiler_compat /tmp/tmp7jf800a9/test.o -laio -o /tmp/tmp7jf800a9/a.out\n",
      "/home/lukashinterleitner/anaconda3/envs/master-thesis/compiler_compat/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "INFO:root:gcc -pthread -B /home/lukashinterleitner/anaconda3/envs/master-thesis/compiler_compat -fno-strict-overflow -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /home/lukashinterleitner/anaconda3/envs/master-thesis/include -fPIC -O2 -isystem /home/lukashinterleitner/anaconda3/envs/master-thesis/include -fPIC -c /tmp/tmpo_tvykwj/test.c -o /tmp/tmpo_tvykwj/test.o\n",
      "INFO:root:gcc -pthread -B /home/lukashinterleitner/anaconda3/envs/master-thesis/compiler_compat /tmp/tmpo_tvykwj/test.o -L/usr -L/usr/lib64 -lcufile -o /tmp/tmpo_tvykwj/a.out\n",
      "/home/lukashinterleitner/anaconda3/envs/master-thesis/compiler_compat/ld: cannot find -lcufile: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T10:42:31.779289Z",
     "start_time": "2024-11-08T10:42:31.767004Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ],
   "id": "af748f64e20a4fa8",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T10:42:32.304626Z",
     "start_time": "2024-11-08T10:42:31.987031Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ],
   "id": "cdeb08b4f6d2957",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T10:42:33.255623Z",
     "start_time": "2024-11-08T10:42:32.360276Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(hf_model_id)\n",
    "tokenizer = AutoTokenizer.from_pretrained(hf_model_id)\n",
    "\n",
    "print(tokenizer.eos_token_id)\n",
    "print(tokenizer.pad_token_id)"
   ],
   "id": "addc6245190d0ee2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50279\n",
      "1\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T10:42:33.344664Z",
     "start_time": "2024-11-08T10:42:33.331787Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset_config = get_dataset_config(model)\n",
    "dataset_config"
   ],
   "id": "2a785ac31470274e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetConfig(chat_template='tulu', preference_chosen_key='chosen', preference_rejected_key='rejected', sft_messages_key='messages', binary_messages_key='messages', label='binary_labels', convert_preference_to_binary_dataset=False, max_token_length=2048, max_prompt_token_length=None, sanity_check=False, sanity_check_max_samples=100, batched=False, load_from_cache_file=True, num_proc=12, train_only_on_prompt=True, ncols=2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T10:42:33.443142Z",
     "start_time": "2024-11-08T10:42:33.433291Z"
    }
   },
   "cell_type": "code",
   "source": [
    "use_gpu = True\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() and use_gpu else 'cpu')\n",
    "device"
   ],
   "id": "c64e2b22c156b3f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T10:43:15.347211Z",
     "start_time": "2024-11-08T10:43:15.332277Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#model.to(device)\n",
    "model.eval() # set to evaluation because we don't need to update weights"
   ],
   "id": "f46f61e1b7ba1240",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OlmoForCausalLM(\n",
       "  (model): OlmoModel(\n",
       "    (embed_tokens): Embedding(50304, 2048, padding_idx=1)\n",
       "    (layers): ModuleList(\n",
       "      (0-15): 16 x OlmoDecoderLayer(\n",
       "        (self_attn): OlmoSdpaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): OlmoRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): OlmoMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): OlmoLayerNorm()\n",
       "        (post_attention_layernorm): OlmoLayerNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): OlmoLayerNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=50304, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T10:43:15.752275Z",
     "start_time": "2024-11-08T10:43:15.739052Z"
    }
   },
   "cell_type": "code",
   "source": "model.num_parameters()",
   "id": "17e45fe6817a215",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1176764416"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T10:43:16.108107Z",
     "start_time": "2024-11-08T10:43:16.088973Z"
    }
   },
   "cell_type": "code",
   "source": "dataset = load_from_disk(lima_filtered_paraphrased_dataset_path)",
   "id": "b94aff18b2d7ddec",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T10:43:16.482928Z",
     "start_time": "2024-11-08T10:43:16.470663Z"
    }
   },
   "cell_type": "code",
   "source": "dataset.column_names",
   "id": "3eb3e15ea55c0ab1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id', 'messages', 'paraphrased_messages']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T10:43:16.823331Z",
     "start_time": "2024-11-08T10:43:16.807371Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create two datasets for original messages and paraphrased messages\n",
    "\n",
    "original_dataset_columns = [\"id\", \"messages\"]\n",
    "paraphrased_dataset_columns = [\"id\", \"paraphrased_messages\"]\n",
    "\n",
    "original_dataset = dataset.select_columns(original_dataset_columns)\n",
    "paraphrased_dataset = dataset.select_columns(paraphrased_dataset_columns)"
   ],
   "id": "80d113df7deefae7",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T10:43:17.177082Z",
     "start_time": "2024-11-08T10:43:17.168456Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(original_dataset.column_names)\n",
    "print(paraphrased_dataset_columns)"
   ],
   "id": "c9130c45e5829b44",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'messages']\n",
      "['id', 'paraphrased_messages']\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T10:43:17.577907Z",
     "start_time": "2024-11-08T10:43:17.567187Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# rename paraphrased messages to messages since open-instruct encode_sft_example only works with 'messages'key\n",
    "paraphrased_dataset = paraphrased_dataset.rename_column(\"paraphrased_messages\", \"messages\")"
   ],
   "id": "e52b95d5fd142f69",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T10:43:17.966102Z",
     "start_time": "2024-11-08T10:43:17.956393Z"
    }
   },
   "cell_type": "code",
   "source": "original_dataset",
   "id": "45c7b281507a435b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'messages'],\n",
       "    num_rows: 988\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T10:43:18.676265Z",
     "start_time": "2024-11-08T10:43:18.666579Z"
    }
   },
   "cell_type": "code",
   "source": "paraphrased_dataset",
   "id": "37fbaaaf4b0f9c40",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'messages'],\n",
       "    num_rows: 988\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T10:43:19.773847Z",
     "start_time": "2024-11-08T10:43:19.384239Z"
    }
   },
   "cell_type": "code",
   "source": "original_dataset_tokenized = prepare_dataset(dataset=dataset, tokenizer=tokenizer, model=model, sample_size=sample_size)",
   "id": "7f41a2fe2aa324e8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tokenizing and reformatting instruction data:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9801b97b56a843fca61d7853f447d257"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Filter:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a757e11345a84c088c50c9c36d91b4b7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T10:43:20.214343Z",
     "start_time": "2024-11-08T10:43:19.851095Z"
    }
   },
   "cell_type": "code",
   "source": "paraphrased_dataset_tokenized = prepare_dataset(dataset=paraphrased_dataset, tokenizer=tokenizer, model=model, sample_size=sample_size)",
   "id": "b052b67bbef85bd1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tokenizing and reformatting instruction data:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "549d819d4813479483b3cf3ee7e06f66"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Filter:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "74f562526cc242e78ed0691ba1e05f21"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T10:45:21.665893Z",
     "start_time": "2024-11-08T10:45:21.525582Z"
    }
   },
   "cell_type": "code",
   "source": [
    "gradients = dict()\n",
    "\n",
    "data = []\n",
    "\n",
    "original_ids = set()\n",
    "paraphrased_ids = set()\n",
    "\n",
    "for original in original_dataset_tokenized:\n",
    "    original_id = original[\"id\"][0][0]\n",
    "    original_ids.add(original_id)\n",
    "    \n",
    "    original_gradients = get_gradients(model, original, device)    \n",
    "    original_flattened_gradients = get_flattened_weight_vector(original_gradients)\n",
    "    \n",
    "    for paraphrased in paraphrased_dataset_tokenized:\n",
    "        paraphrased_id = paraphrased[\"id\"][0][0]\n",
    "        paraphrased_ids.add(paraphrased_id)\n",
    "        \n",
    "        paraphrased_gradients = get_gradients(model, paraphrased, device)\n",
    "        paraphrased_flattened_gradients = get_flattened_weight_vector(paraphrased_gradients)\n",
    "        \n",
    "        similarity = original_flattened_gradients.dot(paraphrased_flattened_gradients)\n",
    "        data.append((original_id, paraphrased_id, 0))"
   ],
   "id": "a0577aca6eaee9a7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lukashinterleitner/anaconda3/envs/master-thesis/lib/python3.12/site-packages/transformers/data/data_collator.py:657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
      "  batch[\"labels\"] = torch.tensor(batch[\"labels\"], dtype=torch.int64)\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = pd.DataFrame(data, columns=['original_id', 'paraphrased_id', 'value'])\n",
    "df_pivot = df.pivot(index='original_id', columns='paraphrased_id', values='value')\n",
    "df_pivot = df_pivot.reindex(index=sorted(original_ids), columns=sorted(paraphrased_ids))"
   ],
   "id": "b8b0a839fd2c51cd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T10:47:16.389701Z",
     "start_time": "2024-11-08T10:47:16.371091Z"
    }
   },
   "cell_type": "code",
   "source": "df_pivot",
   "id": "a01f205efdc36445",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "paraphrased_id  lima_0  lima_1  lima_2  lima_3  lima_4\n",
       "original_id                                           \n",
       "lima_0               0       0       0       0       0\n",
       "lima_1               0       0       0       0       0\n",
       "lima_2               0       0       0       0       0\n",
       "lima_3               0       0       0       0       0\n",
       "lima_4               0       0       0       0       0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>paraphrased_id</th>\n",
       "      <th>lima_0</th>\n",
       "      <th>lima_1</th>\n",
       "      <th>lima_2</th>\n",
       "      <th>lima_3</th>\n",
       "      <th>lima_4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lima_0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lima_1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lima_2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lima_3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lima_4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df_pivot.to_csv(get_gradients_file_path(), index=True, header=True)",
   "id": "8804558a3ae054c1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T11:05:33.051204Z",
     "start_time": "2024-11-06T11:05:33.044899Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# todo: investigate how olmo uses a single training iteration, check masking\n",
    "# todo: add filtering with regard to open instruct (threshold for similarity)\n",
    "# todo: ranking between sampling\n",
    "# todo: tf-idf -> term-frequency inverse-document-frequency\n",
    "# todo: think about explainability vs. similarity"
   ],
   "id": "e1ce277adef4a061",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T11:05:33.120900Z",
     "start_time": "2024-11-06T11:05:33.114491Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# random projections to reduce weight vector size\n",
    "# compare ranking to other algorithms: bm25, tf-idf, (rouge optionally)"
   ],
   "id": "f1b0b36aa660f94e",
   "outputs": [],
   "execution_count": 17
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
