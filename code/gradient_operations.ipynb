{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T21:03:23.706148Z",
     "start_time": "2024-11-07T21:03:23.688586Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# google colab related stuff\n",
    "def is_running_on_colab():\n",
    "    try:\n",
    "        import google.colab\n",
    "        return True\n",
    "    except ImportError:\n",
    "        return False\n",
    "    \n",
    "if is_running_on_colab():\n",
    "    import os\n",
    "    os.chdir(\"/content\")\n",
    "    !git clone https://github.com/lukas-hinterleitner/master-thesis.git\n",
    "    \n",
    "    os.chdir(\"/content/master-thesis\")\n",
    "    !git submodule init\n",
    "    !git submodule update\n",
    "    \n",
    "    !pip uninstall ibis-framework torchvision torchaudio -y\n",
    "    !pip install -r requirements.txt\n",
    "    os.kill(os.getpid(), 9)"
   ],
   "id": "80ad9f31be3b471e",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## !!! \n",
    "## Keep in mind, that the google colab session will crash after executing the above cell. This is necessary to load open-instruct as an editable package. Just continue by executing the next cell.\n",
    "## !!!"
   ],
   "id": "5a0b00095f9ef836"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T21:03:24.100364Z",
     "start_time": "2024-11-07T21:03:24.092414Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# google colab related stuff\n",
    "def is_running_on_colab():\n",
    "    try:\n",
    "        import google.colab\n",
    "        return True\n",
    "    except ImportError:\n",
    "        return False\n",
    "    \n",
    "if is_running_on_colab():\n",
    "    import os\n",
    "    os.chdir(\"/content/master-thesis/code\")"
   ],
   "id": "829271f117d99062",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-07T21:03:41.312235Z",
     "start_time": "2024-11-07T21:03:24.470071Z"
    }
   },
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_from_disk\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import gc\n",
    "\n",
    "from config import hf_model_id, lima_filtered_paraphrased_dataset_path, get_dataset_config\n",
    "\n",
    "from utilities.preprocessing import prepare_dataset\n",
    "from utilities.gradient_operations import get_gradients, get_flattened_weight_vector"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-07 22:03:37,330] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:gcc -pthread -B /home/lukashinterleitner/anaconda3/envs/master-thesis/compiler_compat -fno-strict-overflow -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /home/lukashinterleitner/anaconda3/envs/master-thesis/include -fPIC -O2 -isystem /home/lukashinterleitner/anaconda3/envs/master-thesis/include -fPIC -c /tmp/tmp52v2k_a5/test.c -o /tmp/tmp52v2k_a5/test.o\n",
      "INFO:root:gcc -pthread -B /home/lukashinterleitner/anaconda3/envs/master-thesis/compiler_compat /tmp/tmp52v2k_a5/test.o -laio -o /tmp/tmp52v2k_a5/a.out\n",
      "/home/lukashinterleitner/anaconda3/envs/master-thesis/compiler_compat/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "INFO:root:gcc -pthread -B /home/lukashinterleitner/anaconda3/envs/master-thesis/compiler_compat -fno-strict-overflow -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /home/lukashinterleitner/anaconda3/envs/master-thesis/include -fPIC -O2 -isystem /home/lukashinterleitner/anaconda3/envs/master-thesis/include -fPIC -c /tmp/tmpiw859gct/test.c -o /tmp/tmpiw859gct/test.o\n",
      "INFO:root:gcc -pthread -B /home/lukashinterleitner/anaconda3/envs/master-thesis/compiler_compat /tmp/tmpiw859gct/test.o -L/usr -L/usr/lib64 -lcufile -o /tmp/tmpiw859gct/a.out\n",
      "/home/lukashinterleitner/anaconda3/envs/master-thesis/compiler_compat/ld: cannot find -lcufile: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T21:03:41.336551Z",
     "start_time": "2024-11-07T21:03:41.322856Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ],
   "id": "af748f64e20a4fa8",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T21:03:41.792773Z",
     "start_time": "2024-11-07T21:03:41.400340Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ],
   "id": "cdeb08b4f6d2957",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T21:03:42.797954Z",
     "start_time": "2024-11-07T21:03:41.872152Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(hf_model_id)\n",
    "tokenizer = AutoTokenizer.from_pretrained(hf_model_id)\n",
    "\n",
    "print(tokenizer.eos_token_id)\n",
    "print(tokenizer.pad_token_id)"
   ],
   "id": "addc6245190d0ee2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50279\n",
      "1\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T21:03:42.889532Z",
     "start_time": "2024-11-07T21:03:42.878294Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset_config = get_dataset_config(model)\n",
    "dataset_config"
   ],
   "id": "2a785ac31470274e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetConfig(chat_template='tulu', preference_chosen_key='chosen', preference_rejected_key='rejected', sft_messages_key='messages', binary_messages_key='messages', label='binary_labels', convert_preference_to_binary_dataset=False, max_token_length=2048, max_prompt_token_length=None, sanity_check=False, sanity_check_max_samples=100, batched=False, load_from_cache_file=True, num_proc=12, train_only_on_prompt=True, ncols=2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T21:03:42.993833Z",
     "start_time": "2024-11-07T21:03:42.983273Z"
    }
   },
   "cell_type": "code",
   "source": [
    "use_gpu = True\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() and use_gpu else 'cpu')\n",
    "device"
   ],
   "id": "c64e2b22c156b3f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T21:03:43.106763Z",
     "start_time": "2024-11-07T21:03:43.098209Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.to(device)\n",
    "model.eval() # set to evaluation because we don't need to update weights"
   ],
   "id": "f46f61e1b7ba1240",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T21:03:43.300267Z",
     "start_time": "2024-11-07T21:03:43.275280Z"
    }
   },
   "cell_type": "code",
   "source": "dataset = load_from_disk(lima_filtered_paraphrased_dataset_path)",
   "id": "b94aff18b2d7ddec",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T21:03:43.391549Z",
     "start_time": "2024-11-07T21:03:43.378746Z"
    }
   },
   "cell_type": "code",
   "source": "dataset.column_names",
   "id": "3eb3e15ea55c0ab1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id', 'messages', 'paraphrased_messages']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T21:03:43.518013Z",
     "start_time": "2024-11-07T21:03:43.501567Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create two datasets for original messages and paraphrased messages\n",
    "\n",
    "original_dataset_columns = [\"id\", \"messages\"]\n",
    "paraphrased_dataset_columns = [\"id\", \"paraphrased_messages\"]\n",
    "\n",
    "original_dataset = dataset.select_columns(original_dataset_columns)\n",
    "paraphrased_dataset = dataset.select_columns(paraphrased_dataset_columns)"
   ],
   "id": "80d113df7deefae7",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T21:03:43.583708Z",
     "start_time": "2024-11-07T21:03:43.576062Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(original_dataset.column_names)\n",
    "print(paraphrased_dataset_columns)"
   ],
   "id": "c9130c45e5829b44",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'messages']\n",
      "['id', 'paraphrased_messages']\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T21:03:43.742541Z",
     "start_time": "2024-11-07T21:03:43.730696Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# rename paraphrased messages to messages since open-instruct encode_sft_example only works with 'messages'key\n",
    "paraphrased_dataset = paraphrased_dataset.rename_column(\"paraphrased_messages\", \"messages\")"
   ],
   "id": "e52b95d5fd142f69",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T21:03:43.824478Z",
     "start_time": "2024-11-07T21:03:43.812877Z"
    }
   },
   "cell_type": "code",
   "source": "original_dataset",
   "id": "45c7b281507a435b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'messages'],\n",
       "    num_rows: 988\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T21:03:44.102164Z",
     "start_time": "2024-11-07T21:03:44.093164Z"
    }
   },
   "cell_type": "code",
   "source": "paraphrased_dataset",
   "id": "37fbaaaf4b0f9c40",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'messages'],\n",
       "    num_rows: 988\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T21:03:44.330856Z",
     "start_time": "2024-11-07T21:03:44.324354Z"
    }
   },
   "cell_type": "code",
   "source": "sample_size = 5",
   "id": "3ff7d92d88aef19e",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T21:03:44.898124Z",
     "start_time": "2024-11-07T21:03:44.618115Z"
    }
   },
   "cell_type": "code",
   "source": "original_dataset_tokenized = prepare_dataset(dataset=dataset, tokenizer=tokenizer, model=model, sample_size=sample_size)",
   "id": "7f41a2fe2aa324e8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tokenizing and reformatting instruction data:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b7d9ebc6bc894abc9213230d28df4216"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T21:04:25.608881Z",
     "start_time": "2024-11-07T21:04:25.292148Z"
    }
   },
   "cell_type": "code",
   "source": "paraphrased_dataset_tokenized = prepare_dataset(dataset=paraphrased_dataset, tokenizer=tokenizer, model=model, sample_size=sample_size)",
   "id": "b052b67bbef85bd1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tokenizing and reformatting instruction data:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a645722168c64aaf92ec214ca627e629"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Filter:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "82708e76edd44ca5bdaa6d07ebc78d07"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T21:55:14.959001Z",
     "start_time": "2024-11-07T21:54:41.835179Z"
    }
   },
   "cell_type": "code",
   "source": [
    "gradients = dict()\n",
    "\n",
    "for original in original_dataset_tokenized:\n",
    "    original_id = original[\"id\"][0][0]\n",
    "    \n",
    "    original_gradients = get_gradients(model, original, device)\n",
    "    original_flattened_gradients = get_flattened_weight_vector(gradients).to(device)\n",
    "    \n",
    "    for paraphrased in paraphrased_dataset_tokenized:\n",
    "        paraphrased_id = paraphrased[\"id\"][0][0]\n",
    "        \n",
    "        paraphrased_gradients = get_gradients(model, paraphrased, device)\n",
    "        paraphrased_flattened_gradients = get_flattened_weight_vector(paraphrased_gradients).to(device)\n",
    "        \n",
    "        gradients[(original_id, paraphrased_id)] = original_flattened_gradients.dot(paraphrased_flattened_gradients)"
   ],
   "id": "a0577aca6eaee9a7",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "torch.cat(): expected a non-empty list of Tensors",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[24], line 7\u001B[0m\n\u001B[1;32m      4\u001B[0m original_id \u001B[38;5;241m=\u001B[39m original[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mid\u001B[39m\u001B[38;5;124m\"\u001B[39m][\u001B[38;5;241m0\u001B[39m][\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m      6\u001B[0m original_gradients \u001B[38;5;241m=\u001B[39m get_gradients(model, original)\n\u001B[0;32m----> 7\u001B[0m original_flattened_gradients \u001B[38;5;241m=\u001B[39m get_flattened_weight_vector(gradients)\u001B[38;5;66;03m#.to(device)\u001B[39;00m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m paraphrased \u001B[38;5;129;01min\u001B[39;00m paraphrased_dataset_tokenized:\n\u001B[1;32m     10\u001B[0m     paraphrased_id \u001B[38;5;241m=\u001B[39m paraphrased[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mid\u001B[39m\u001B[38;5;124m\"\u001B[39m][\u001B[38;5;241m0\u001B[39m][\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[0;32m~/Documents/Master_Data_Science/Master_Thesis/code/utilities/gradient_operations.py:27\u001B[0m, in \u001B[0;36mget_flattened_weight_vector\u001B[0;34m(weight_dict)\u001B[0m\n\u001B[1;32m     24\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m weights \u001B[38;5;129;01min\u001B[39;00m weight_dict\u001B[38;5;241m.\u001B[39mvalues():\n\u001B[1;32m     25\u001B[0m     flattened_weights\u001B[38;5;241m.\u001B[39mappend(weights\u001B[38;5;241m.\u001B[39mflatten())\n\u001B[0;32m---> 27\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcat(flattened_weights)\n",
      "\u001B[0;31mRuntimeError\u001B[0m: torch.cat(): expected a non-empty list of Tensors"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T21:06:14.474692Z",
     "start_time": "2024-11-07T21:06:14.459918Z"
    }
   },
   "cell_type": "code",
   "source": "gradients",
   "id": "645933176121d9fd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('lima_0', 'lima_0'): 0,\n",
       " ('lima_0', 'lima_1'): 0,\n",
       " ('lima_0', 'lima_2'): 0,\n",
       " ('lima_0', 'lima_3'): 0,\n",
       " ('lima_0', 'lima_4'): 0,\n",
       " ('lima_1', 'lima_0'): 0,\n",
       " ('lima_1', 'lima_1'): 0,\n",
       " ('lima_1', 'lima_2'): 0,\n",
       " ('lima_1', 'lima_3'): 0,\n",
       " ('lima_1', 'lima_4'): 0,\n",
       " ('lima_2', 'lima_0'): 0,\n",
       " ('lima_2', 'lima_1'): 0,\n",
       " ('lima_2', 'lima_2'): 0,\n",
       " ('lima_2', 'lima_3'): 0,\n",
       " ('lima_2', 'lima_4'): 0,\n",
       " ('lima_3', 'lima_0'): 0,\n",
       " ('lima_3', 'lima_1'): 0,\n",
       " ('lima_3', 'lima_2'): 0,\n",
       " ('lima_3', 'lima_3'): 0,\n",
       " ('lima_3', 'lima_4'): 0,\n",
       " ('lima_4', 'lima_0'): 0,\n",
       " ('lima_4', 'lima_1'): 0,\n",
       " ('lima_4', 'lima_2'): 0,\n",
       " ('lima_4', 'lima_3'): 0,\n",
       " ('lima_4', 'lima_4'): 0}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T11:05:32.927284Z",
     "start_time": "2024-11-06T11:05:32.917267Z"
    }
   },
   "cell_type": "code",
   "source": "#flattened_gradients.size()",
   "id": "b531332c6bc28f41",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1176764416])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T11:05:33.051204Z",
     "start_time": "2024-11-06T11:05:33.044899Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# todo: investigate how olmo uses a single training iteration, check masking\n",
    "# todo: add filtering with regard to open instruct (threshold for similarity)\n",
    "# todo: ranking between sampling\n",
    "# todo: tf-idf -> term-frequency inverse-document-frequency\n",
    "# todo: think about explainability vs. similarity"
   ],
   "id": "e1ce277adef4a061",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T11:05:33.120900Z",
     "start_time": "2024-11-06T11:05:33.114491Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# random projections to reduce weight vector size\n",
    "# compare ranking to other algorithms: bm25, tf-idf, (rouge optionally)"
   ],
   "id": "f1b0b36aa660f94e",
   "outputs": [],
   "execution_count": 17
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
